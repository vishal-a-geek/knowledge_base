- Advertised as "infinitely scaling" storage
	- Many websites use S3 as a backbone
	- Many AWS services use S3 as an integration as well


## Use cases
- Backup & storage
- Disaster Recovery
- Archive
- Hybrid Cloud storage
- Application hosting
- Media hosting
- **Data lakes & big data analytics**
- Software delivery
- Static website
- E.g.
	- Nasdaq stores 7 years of data into S3 Glacier
	- Sysco runs analytics on its data and gain business insights

## Buckets
- S3 stores files into buckets (can be seen as top-level directories)
-  Files in these S3 buckets are called objects
- Buckets must have a globally unique name (name unique across all regions and all accounts)
- Buckets are defined at region level
	- Even if name of bucket is same at all regions and accounts
	- S3 looks like a global service but buckets are created in a region
- Naming convention for bucket name
	- no uppercase, no underscore
	- 3-63 characters long
	- not an ip
	- must start with lowercase letter or number
	- must not start with prefix `xn--`
	- must not end with suffix `-s3alias`

## Objects
- Files in a bucket are called objects
- Files have a key
- key is the full path of the file/object
	- s3://my-bucket/my_file.txt
	- s3://my-bucket/my_folder1/another_folder/my_file.txt
- The key is composed of **prefix** + ***object name***
	- s3://**myt keys -bucket/my_folder1/another_folder**/***my_file.text***
		- prefix: **my_folder1/another_folder**
		- object name: ***my_file.txt***
- There's no concept of directories within buckets
	- Although the UI will trick you to think otherwise
	- But everything in s3 is a **key**
- Keys are with very long names that contain slashes
- Object values are content of the body
	- Max object size is 5TB (5000 GB)
	- If uploading more than 5GB, must use multi-part upload
- Objects can also have metadata
	- List of text key / value pairs - system or user metadata 
- Objects can have tags
	- useful for security / lifecycle
- Objects can have version ID if versioning is enabled
- S3 **pre-signed** URL for object URL
	- This **pre-signed** URL is generated while clicking on "Open ->" button on an S3 bucket, which is different than just the Object URL ![[Pasted image 20250404095736.png]]
	- pre-signed URL:
		- ![[Pasted image 20250404095920.png]]
	- Plain object URL:![[Pasted image 20250404100004.png]]

## S3 Security
 - User Based
	 - [[IAM]] Policies
		 - which API calls should be allowed for a specific user from [[IAM]]
- Resource Based
	- **Bucket policies** (most commonly used now)
		- bucket wide rules from S3 console to allow cross account
	- Object Access Control List(ACL) - fine grain
	- Bucket Access Control List - less common
- an [[IAM]] principal can access S3 object if
	- user's 
		- [[IAM]] permissions ALLOW it
		- OR the resource policy ALLOWS it
	- AND no explicit DENY
- **Encryption**: encrypt objects in S3 using encryption keys

### S3 Bucket policies
- JSON Based Policies 
	- **`Resource` block**: which bucket(s)/object(s) the policy applies on
		- `"arn:aws:s3:::examplebucket/*"` means applied on **every object**(\*) inside `examplebucket`
	- **`Effect` of action**: Allow/Deny
	- **`Action`**: Set of APIs to Allow/Deny
		- `"s3:GetObject"`
	- **`Principal`**: The account or user to apply the policy to
		- \* means to anyone
```json 
// Grants public read access to the bucket
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "PublicRead",
			"Effect": "Allow",
			"Principal": "*",
			"Action": [
				"s3:GetObject"
			],
			"Resource": [
				"arn:aws:s3:::examplebucket/*"
			]
		}
	]
}```

### Use cases of S3 bucket policy
- Grant public access to bucket
- Force objects to be encrypted at upload
- Grant access to another account (cross account)
### Example: 
- **Public Access**
	- Use Bucket Policy
- **[[IAM]] User Access to S3**
	- Use [[IAM]] permissions/policy
- **[[EC2]] instance access**
	- Use [[IAM]] Roles with correct [[IAM]] permissions
- **Cross-Account Access**
	- [[IAM]] User other AWS account
	- Use Bucket Policy


## AWS S3 - Replication (CRR & SRR)
- CRR: Cross Region Replication
- SRR: Same Region Replication
- Setup asynchronous replication between two buckets
- **Versioning must be enabled**
- Buckets can be in different AWS accounts
- Copying is asynchronous (behind the scenes in the background)
- Proper [[IAM]] permissions to S3

### Use case of Replication:
- CRR- Compliance, lower latency access, replication across accounts
- SRR
	- log aggregation across multiple buckets
	- live replication between prod and test accounts
- After enabling Replication, only new objects are replicated
	- to replicate existing objects, use **S3 batch replication**
		- Replicates existing objects that failed replication
- For delete operations
	- Replicate delete markers (deletion after versioning)
	- Deletions with a version ID are not replicated (to avoid malicious deletes)
- There's no **"chaining"** of replication
	- If bucket 1 -> replicates into bucket 2 and bucket 2 -> replicates into bucket 3
		- Then objects of bucket 1 are not replicated to bucket 3


## S3 Storage Classes
- **Standard - General Purpose**
	- 99.99% availability
	- Used for frequently accessed data
	- Low latency and high throughput
	- Sustain 2 concurrent facility failures
	- **Use cases**:
		- Big Data analytics
		- Mobile & Gaming applications
		- Content distribution
- **Infrequent Access (IA)**
	- **Standard-IA (Infrequent Access)**
		- Less frequently accessed but requires rapid access when needed
		- Lower cost than S3 standard
			- Has cost on retrieval
		- 99.9% availability
		- **Use cases**:
			- Disaster Recovery
			- Backups
	- **One Zone IA**
		- High durability in a single AZ
		- Data will be lost when the AZ is destroyed
		- 99.5% availability
		- **Use cases:**
			- Storing secondary backup copies of on-premise data
			- data u can recreate
- **Glacier Storage Classes**: Low-cost object storage for archiving and backup with pricing for storage and object retrieval cost
	- **Glacier Instant Retrieval**
		- Millisecond retrieval (for data accessed once a quarter)
		- Minimum storage duration of 90 days
	- **Glacier Flexible Retrieval**: Willing to wait for retrieval
		- **Expedited**: 1 to 5 minutes retrieval
		- **Standard**: 3 to 5 hours retrieval
		- **Bulk**: 5 to 12 hours retrieval - free
		- Minimum storage duration of 90 days
	- **Glacier Deep Archive**
		- Standard: 12 hours retrieval
		- Bulk: 48 hours retrieval
		- Minimum storage duration of 180 days
- **S3 Intelligent Tiering**
	- Small monthly monitoring and auto-tiering fee
	- Moves objects automatically between access tiers based on usage
	- There are **no retrieval charges** in S3 Intelligent-Tiering
		- Frequent Access tier (automatic) (default tier)
		- Infrequent Access tier (automatic)
			- objects not accessed for **30 days**
		- Archive Instant Access tier (automatic)
			- objects not accessed for **90 days**
		- Archive Access Tier (optional):
			- configurable from **90 days to 700+ days**
		- Deep Archive Access Tier (optional):
			- configurable from **180 days to 700+ days**

- Can move between classes manually or using S3 lifecycle configurations

|                                        | Standard                             | Intelligent-tiering                  | Standard - IA                      | One-Zone IA                       | Glacier Instant Retrieval         | Glacier Flexible Retrieval                                                                             | Glacier Deep Archive                                                               |
| -------------------------------------- | ------------------------------------ | ------------------------------------ | ---------------------------------- | --------------------------------- | --------------------------------- | ------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------- |
| Durability                             | 99.99999999999% = 11 9's             | 11 9's                               | 11 9's                             | 11 9's                            | 11 9's                            | 11 9's                                                                                                 | 11 9's                                                                             |
| Availability                           | 99.99%                               | 99.9%                                | 99.9%                              | 99.5%                             | 99.9%                             | 99.99%                                                                                                 | 99.99%                                                                             |
| Availability SLA                       | 99.9%                                | 99%                                  | 99%                                | 99%                               | 99%                               | 99.9%                                                                                                  | 99.9%                                                                              |
| No.of Availability Zones used to store | >= 3                                 | >= 3                                 | >= 3                               | 1                                 | >= 3                              | >= 3                                                                                                   | >= 3                                                                               |
| Min. Storage Duration Charge           | None                                 | None                                 | 30 Days                            | 30 Days                           | 90 Days                           | 90 Days                                                                                                | 180 Days                                                                           |
| Min. Billable Object Size              | None                                 | None                                 | 128 KB                             | 128 KB                            | 128 KB                            | 40 KB                                                                                                  | 40 KB                                                                              |
| Retrieval Fee                          | None                                 | None                                 | Per GB retrieved                   | Per GB retrieved                  | Per GB retrieved                  | Per GB retrieved                                                                                       | Per GB retrieved                                                                   |
| Storage Cost (per GB per month)        | $0.023                               | $0.0025-$0.023                       | %0.0125                            | $0.01                             | $0.004                            | $0.0036                                                                                                | $0.00099                                                                           |
| Retrieval Cost (per 1000 request)      | **GET**: $0.0004<br>**POST**: $0.005 | **GET**: $0.0004<br>**POST**: $0.005 | **GET**: $0.001<br>**POST**: $0.01 | **GET**: $0.01<br>**POST**: $0.02 | **GET**: $0.01<br>**POST**: $0.02 | **GET**: $0.0004<br>**POST**: $0.03<br><br>**Expedited**: $10<br>**Standard**: $0.05<br>**Bulk**: free | **GET**: $0.0004<br>**POST**: $0.05<br><br>**Standard**: $0.10<br>**Bulk**: $0.025 |
| Retrieval Time                         | Instantaneous                        | Instantaneous                        | Instantaneous                      | Instantaneous                     | Instantaneous                     | **Expedited**: (1-5 mins)<br>**Standard**: (3-5 hours)<br>**Bulk**: (5-12 hours)                       | **Standard**: (12 hours)<br>**Bulk**: (48 hours)                                   |
| Monitoring Cost (per 1000 objects)     |                                      | $0.0025                              |                                    |                                   |                                   |                                                                                                        |                                                                                    |
### S3 Durability and Availability
- Durability
	- Represents how many times an object (file) is going to be lost by S3
	- High durability (99.99999999999, **11 9's**) of objects across multiple AZ
		- If you store 10 M (10,000,000) objects with S3, you can on average expect to incur a loss of single object every 10,000 years
	- Durability is same for all storage classes
- Availability
	- Measures how readily available a service is
	- Varies depending on storage class
	- S3 Standard storage class has 99.99% availability
		- not available 53 minutes a year
### Moving between Storage Class (All possible permutations)
- Standard -> 
	- Standard IA
	- Intelligent Tiering
	- One-Zone IA
	- Glacier Instant
	- Glacier Flexible Retrieval
	- Glacier Deep Archive
- Standard IA -> 
	- Intelligent Tiering
	- One-Zone IA
	- Glacier Instant
	- Glacier Flexible Retrieval
	- Glacier Deep Archive
- Intelligent Tiering
	- One-Zone IA
	- Glacier Instant
	- Glacier Flexible Retrieval
	- Glacier Deep Archive
- One-Zone IA
	- Glacier Instant
	- Glacier Flexible Retrieval
	- Glacier Deep Archive
- Glacier Instant
	- Glacier Flexible Retrieval
	- Glacier Deep Archive
- Glacier Flexible Retrieval
	- Glacier Deep Archive
### Lifecycle Rules
![[Pasted image 20250404125319.png]]
- **Transition Actions**
	- configure objects to transition to another storage class
	- Move objects to Standard IA class 60 days after creation
	- Move to Glacier for archiving after 6 months
- **Expiration Actions**
	- configure objects to expire (delete) after sometime. Examples:
		- delete log files after 365 days
		- delete old versions of files (if versioning is enabled)
		- delete incomplete Multi-Part uploads

- Rules can be created for 
	- a certain prefix 
		- example prefix: `s3://mybucket/mp3/*`
	- certain object tags
		- example: `Department: Finance`

#### Lifecycle Rules (Scenarios)
![[Pasted image 20250404153956.png]]
##### Scenario 1
- Your application on [[EC2]] creates images thumbnails after profile photos are uploaded to S3.
- These thumbnails can be easily recreated, and only need to be kept for 60 days.
- The source images should be able to be immediately retrieved for these 60 days, and afterwards the user can wait upto 6 hours.
- How would you design this?
###### Design
- **source images** on **Standard** with lifecycle configuration(rule) to transition them to **Glacier** after 60 days
	- **Standard** for immediate access for 60 days
	- **Glacier** because user can wait upto 6 hours after 60 days
- **thumbnails** can be on **One-Zone IA** with a lifecycle configuration to expire them after 60 days
	- Because they are only needed to be kept for 60 days and not needed after 60 days, thus no point in storing in more than 1 AZ
- can use prefix based rule to differentiate between **thumbnails** and **source images**

##### Scenario 2
- should be able to recover your deleted S3 objects **immediately** for 30 days, although this may happen **rarely**
- After 30 days, deleted objects should be recoverable within 48 hours
###### Design
- S3 bucket versioning should be enabled
	- so that deleted objects are in fact hidden by a **"delete marker"** and can be recovered
- Transition "non-current versions" (with **delete marker**) of the object to **Standard IA** for 30 days
	- For **immediate access** -> **Standard**
	- This may happen **rarely** (infrequent access) -> **IA**
- Transition "non-current versions" to **Glacier Deep Archive** after 60 days of deletion

#### Storage Class Analysis
- Helps to decide optimum number of days for transition/expiration actions, thus **improve** the **Lifecycle Rules**
- Recommendations for **Standard** and **Standard IA**
	- Does **not** work for One-Zone IA or Glacier
- S3 buckets will have S3 analytics run on top of it
	- This creates a `.csv` report with some recommendations and statistics
	- Report is updated daily
	- Can take between 24 to 48 hours to start seeing data analysis coming out of the S3 analytics


## S3 Event Notifications
- Examples: 
	- S3:ObjectCreated
	- S3:ObjectRemovedd
	- S3:Replication
- All Set of Possible Event Types:
- We can filter among the events to listen on
	- E.g. objects that end with (\*.jpg)
- **Use case**: automatically generate thumbnails of images uploaded to S3
- S3 Event notification can be sent to
	- SNS Topic
	- SQS Queue
	- Lambda Function
- Can create as many S3 events as desired
- These event notifications are typical delivered within seconds but can take minutes or longer sometimes
- Need [[IAM]] permissions for S3 Event Notification to work
- If S3 to be able to send Event notification to a SNS Topic, the S3 bucket should have attached a SNS Resource (Access) Policy
```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "AllowNotify",
			"Effect": "Allow",
			"Principal": {
				"Service": "s3.amazonaws.com"
			},
			"Action": "SNS:Publish",
			"Resource": "arn:aws:sns::us-east-1:12345664324:MySNSTopic",
			"Condition": {
				"ArnLike": {
					"aws.SourceArn": "arn:aws:s3:::MyBucket"
				}
			}
		}
	]
}
```
- If S3 to be able to send Event notification to a SQS Queue, the S3 bucket should have attached a SQS Resource (Access) Policy
```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "AllowNotify",
			"Effect": "Allow",
			"Principal": {
				"Service": "s3.amazonaws.com"
			},
			"Action": "SQS:SendMessage",
			"Resource": "arn:aws:sns::us-east-1:12345664324:MySQSQueue",
			"Condition": {
				"ArnLike": {
					"aws.SourceArn": "arn:aws:s3:::MyBucket"
				}
			}
		}
	]
}
```
- If S3 to be able to send Event notification to a Lambda function, the S3 bucket should have attached a Lambda Access Policy
```json
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "AllowNotify",
			"Effect": "Allow",
			"Principal": {
				"Service": "s3.amazonaws.com"
			},
			"Action": "lambda:InvokeFunction",
			"Resource": "arn:aws:sns::us-east-1:12345664324:function:MyFunction",
			"Condition": {
				"ArnLike": {
					"aws.SourceArn": "arn:aws:s3:::MyBucket"
				}
			}
		}
	]
}
```
- Here we don't use [[IAM]] Roles for S3, instead we define Resource Access Policy on
	- SNS Topic
	- SQS Queue
	- Lambda Function

![[Pasted image 20250404201724.png]]
![[Pasted image 20250404202104.png]]
![[Pasted image 20250404201846.png]]
![[Pasted image 20250404201815.png]]
### S3 Events with Amazon EventBridge
- S3 Events -> S3 Bucket -> EventBridge
- All events (no matter which) go to the EventBridge
- From EventBridge we can set rules which can further send to 18 other AWS services as destinations
- Note: Event notifications can only be sent to either **SQS/SNS/Lambda**. For sending to other places, use **Amazon EventBridge**.



## S3 performance
- S3 Automatically scales to high request rates, latency 100-200 ms
- Applications can achieve at least 3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD **per second per prefix** in a bucket
	- it means a really really high performance
	- There are no limits on number of prefixes in a bucket

| object path                  | prefix          | per second per prefix                                                           |
| ---------------------------- | --------------- | ------------------------------------------------------------------------------- |
| bucket/folder-1/sub-1/file-1 | /folder-1/sub-1 | for this **file-1**, in this prefix, we can get 3500  PUTs 5500 GETs per second |
| bucket/folder-1/sub-2/file-2 | /folder-1/sub-2 | for this **file-2**, in this prefix, we can 3500 PUTs 5500 GETs per second      |

### How to optimise S3 performance
- **Multi-part upload**
	- recommended for files > 100MB
	- must use for files > 5GB
		- Can help parallelise uploads (speeds up transfers)
- **S3 Transfer Acceleration**
	- Increase transfer speed by transferring file to an **AWS edge location** which will forward the data to S3 bucket in the target region
	- Compatible with multi-part upload
	- File in USA -> Upload to edge location in USA -> Upload to S3 bucket in Australia
- **S3 Byte-Range Fetches**
	- Parallelise GETs by requesting specific byte ranges
	- Better resilience in case of failures
	- **Use cases**:
		- Speed up downloads by parallelising requests
		- Retrieve only partial data of a file
			- may be just the header of a file if we know the header size
## S3 Encryption
- Can encrypt objects in S3 buckets using one of 4 methods:
- With S3 managed keys (**SSE-S3**)
	- This is enabled by default for buckets and objects
- With KMS Keys stored in AWS KMS (**SSE-KMS**)
	- Leverage Key Management Service (AWS KMS) to manage encryption keys
- With Customer-Provided Keys (**SSE-C**)
	- While managing own encryption keys

- It's important to understand which encryption should be used for which situation


| S3 Managed (SSE-S3)                                                                                                          | SSE-KMS                                                                        | SSE-C                                                                       | Client Side Encryption                                                 |
| ---------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------ | --------------------------------------------------------------------------- | ---------------------------------------------------------------------- |
| keys handled, managed and owned by AWS                                                                                       | keys handled and managed by **AWS KMS** (Key Management Service)               | keys fully managed by **customer** outside of S3                            | easy to implement if we leverage some client side encryption libraries |
| we never have access to the keys                                                                                             | user control + audit key usage in CloudTrail                                   | S3 does **NOT** store the provided encryption key                           | clients must encrypt data themselves, before sending to S3             |
| Object is encrypted server side                                                                                              | header: `"x-amz-server-side-encryption":"aws:kms"`                             | **HTTPS** must be used                                                      | client must decrypt the data themselves after retrieving from S3       |
| Encryption type is **AES-256**                                                                                               | while reading the file, need the access to KMS being  used                     | Encryption key must be provided in HTTP headers for every HTTP request made | customer fully manages key and the encryption cycle                    |
| Must set header **`"x-amz-server-side-encryption":"AES256"`** to request S3 to encrypt the object using **SSE-S3** mechanism | KMS key has limits. During **encryption** and **decryption**, it uses KMS APIs |                                                                             |                                                                        |
| This is enabled by default for new buckets and new objects                                                                   | Count towards the KMS quota per second                                         |                                                                             |                                                                        |

### Encryption in transit or in flight (SSL/TLS)
- Encryption in flight is also called SSL/TLS
- S3 has two endpoints:
- **HTTP Endpoint** - non encrypted
- **HTTPS Endpoint**- encryption in flight
### Force Encryption in Transit (`aws:SecureTransport`)
- Using a bucket policy
```json
// Deny any s3:GetObject operation on the S3 bucket, if `aws:SecureTransport` is false
// aws:SecureTransport is going to be true while using HTTPS and false while using HTTP
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "ForceEncryptionInTransit",
			"Effect": "Deny",
			"Principal": "*",
			"Action": [
				"s3:GetObject"
			],
			"Resource": [
				"arn:aws:s3:::examplebucket/*"
			],
			"Condition": {
    			"Bool": {
        			"aws:SecureTransport": "false"
    			}
			}
		}
	]
}
```


### Default Encryption Vs Bucket Policies
- SSE-S3 (default encryption) encryption is automatically applied to new objects stored in S3 bucket
- Can force encryption on S3 bucket using bucket policy and refuse any API call to PUT an S3 object without encryption headers (SSE-KMS or SSE-C)
```json
// Forces SSE-KMS
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "ForceKMSEncryption",
			"Effect": "Deny",
			"Principal": "*",
			"Action": [
				"s3:PutObject"
			],
			"Resource": [
				"arn:aws:s3:::examplebucket/*"
			],
			"Condition": {
    			"StringNotEquals": {
        			"s3:x-amz-server-side-encryption": "aws:kms"
    			}
			}
		}
	]
}

// Forces SSE-C
{
	"Version": "2012-10-17",
	"Statement": [
		{
			"Sid": "ForceKMSEncryption",
			"Effect": "Deny",
			"Principal": "*",
			"Action": [
				"s3:PutObject"
			],
			"Resource": [
				"arn:aws:s3:::examplebucket/*"
			],
			"Condition": {
    			"Null": {
        			"s3:x-amz-server-side-encryption-customer-algorithm": "true"
    			}
			}
		}
	]
}
```
## S3 Access Points
 